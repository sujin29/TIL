{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 데이터 전처리\n",
    "ML 알고리즘은 데이터에 기반하고 있기 때문에 어떤 데이터를 입력으로 가지느냐에 따라 결과도 크게 달라질 수 있다. 사이킷런의 ML 알고리즘을 적용하기 전에 데이터에 대해 미리 처리해야 할 기본 사항이 있다.  \n",
    "**결손값, 즉 NaN, Null 값은 허용되지 않는다.** 고정된 다른 값으로 변환해야 한다. 처리방법은 경우에 따라 다르다. \n",
    "피처값 중 Null 값이 얼마 되지 않는다면 피처의 평균값 등으로 대체.\n",
    "Null 값이 대부분이라면 해당 피처를 드롭하는 것이 더 좋다.\n",
    "Null 값이 일정 수준 이상 되는 경우는 결정하기 힘들다. 중요도가 높은 피처이고 Null을 단순히 피처의 평균값으로 대체할 경우 예측 왜곡이 심할 수 있다면 업무 로직 등을 상세히 검토해 더 정밀한 대체 값을 선정해야 한다.  \n",
    "사이킷런의 머신러닝 알고리즘은 **문자열 값을 입력 값으로 허용하지 않는다.** 모든 문자열 값은 인코딩해서 숫자형으로 변환해야 한다. 문자열 피처는 일반적으로 카테고리형 피처와 텍스트형 피처를 의미한다. 카테고리형 피처는 코드값으로 표현. 텍스트형 피처는 피처 벡터화 등으로 벡터화하거나 불필요하다고 판단되면 삭제. 식별자 피처(주민번호, 단순 문자열 아이디)는 단순히 데이터 로우를 식별하는 용도로 사용되기 때문에 예측에 중요한 요소가 될 수 없으며 알고리즘을 오히려 복잡하게 만들고, 예측 성능을 떨어트린다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 인코딩\n",
    "머신러닝을 위한 대표적인 인코딩 방식 - 레이블 인코딩(Lable encoding), 원-핫 인코딩(One Hot encoding)  \n",
    "### 레이블 인코딩\n",
    "카테고리 피처를 코드형 숫자 값으로 변환하는 것. '01', '02'와 같은 코드 값 역시 문자열이므로 1, 2와 같은 숫자형 값으로 변환해야 한다.  \n",
    "사이킷런의 레이블 인코딩(Lable encoding)은 LabelEncoder 클래스로 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 변환 값:  [0 1 4 5 3 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', \n",
    "         '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# LabelEncoder를 객체로 생성한 후, fit()과 transform()으로 레이블 인코딩\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "\n",
    "print('인코딩 변환 값: ', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩 클래스:  ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']\n"
     ]
    }
   ],
   "source": [
    "print('인코딩 클래스: ', encoder.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classes_ 속성은 0번부터 순서대로 변환된 인코딩 값에 대한 원본 값을 가지고 있다.  \n",
    "`inverse_transform()`을 통해 인코딩된 값을 다시 디코딩할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코딩 원본값:  ['TV' '냉장고' '전자레인지' '컴퓨터' '선풍기' '선풍기' '믹서' '믹서']\n"
     ]
    }
   ],
   "source": [
    "print('디코딩 원본값: ', encoder.inverse_transform([0, 1, 4, 5, 3, 3, 2, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블 인코딩은 간단하게 문자열 값을 숫자형 카테고리 값으로 변환. 하지만 레이블 인코딩이 일괄적인 숫자 값으로 변환이 되면서 몇몇 ML 알고리즘에는 이를 적용할 경우 예측성능이 떨어진다. 숫자 값의 경우 크고 작음에 대한 특성이 작용하기 때문. (큰 숫자에 가중치가 더 부여되거나 더 중요하다고 인식하는 가능성이 발생) 이러한 특성 때문에 레이블 인코딩은 선형회귀와 같은 ML 알고리즘에는 적용하지 않아야 한다. 트리계열의 ML 알고리즘은 이러한 특성을 반영하지 않으므로 레이블 인코딩도 별 문제 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원-핫 인코딩(One-Hot Encoding)\n",
    "피처 값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 컬럼에만 1을 표시하고 나머지 컬럼에는 0을 표시하는 방식. 즉, 행 형태로 되어있는 피처의 고유 값을 열 형태로 차원을 변환한 뒤, 고유 값에 해당하는 컬럼에만 1을 표시하고 나머지 컬럼에는 0을 표시한다.  \n",
    "원-핫 인코딩은 사이킷런에서 OneHotEncoder 클래스로 쉽게 변환 가능하다. 단, LabelEncoder와 다르게 주의할 점이 있다.\n",
    "1. OneHotEncoder로 변환하기 전에 모든 문자열 값이 숫자형 값으로 변환돼야 한다.\n",
    "2. 입력값으로 2차원 데이터가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원-핫 인코딩 데이터\n",
      "[[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "원-핫 인코딩 데이터차원\n",
      "(8, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "items = ['TV', '냉장고', '전자레인지', '컴퓨터', \n",
    "         '선풍기', '선풍기', '믹서', '믹서']\n",
    "\n",
    "# 숫자 값으로 변환하기 위해 LabelEncoder로 변환\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "\n",
    "# 2차원 데이터로 변환\n",
    "labels = labels.reshape(-1, 1)\n",
    "\n",
    "# 원-핫 인코딩 적용\n",
    "oh_encoder = OneHotEncoder()\n",
    "oh_encoder.fit(labels)\n",
    "oh_labels = oh_encoder.transform(labels)\n",
    "\n",
    "print('원-핫 인코딩 데이터')\n",
    "print(oh_labels.toarray())\n",
    "\n",
    "print('원-핫 인코딩 데이터차원')\n",
    "print(oh_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원-핫 인코딩을 더 쉽게 지원하는 판다스 API - `get_dummies()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_TV</th>\n",
       "      <th>item_냉장고</th>\n",
       "      <th>item_믹서</th>\n",
       "      <th>item_선풍기</th>\n",
       "      <th>item_전자레인지</th>\n",
       "      <th>item_컴퓨터</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_TV  item_냉장고  item_믹서  item_선풍기  item_전자레인지  item_컴퓨터\n",
       "0        1         0        0         0           0         0\n",
       "1        0         1        0         0           0         0\n",
       "2        0         0        0         0           1         0\n",
       "3        0         0        0         0           0         1\n",
       "4        0         0        0         1           0         0\n",
       "5        0         0        0         1           0         0\n",
       "6        0         0        1         0           0         0\n",
       "7        0         0        1         0           0         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'item': ['TV', '냉장고', '전자레인지', '컴퓨터', \n",
    "         '선풍기', '선풍기', '믹서', '믹서']\n",
    "})\n",
    "pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "숫자형 값으로 변환 없이도 바로 변환이 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 피처 스케일링과 정규화\n",
    "피처 스케일링(feature scaling) - 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업. 대표적인 방법으로 표준화(Standardization)와 정규화(Normalization)가 있다.\n",
    "\n",
    "**표준화 (Standardization)**  \n",
    "- 데이터의 피처 각각이 평균이 0이고 분산이 1인 가우시안 정규 분포를 가진 값으로 변환하는 것\n",
    "- (x - x의 평균) / 표준편차\n",
    "\n",
    "**정규화 (Noramalization)**\n",
    "- 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해주는 개념\n",
    "- 변수를 모두 동일한 크기 단위로 비교하기 위해 값을 모두 0 ~ 1의 값으로 변환하는 것 -> 개별 데이터의 크기를 모두 똑같은 단위로 변경\n",
    "- (x - x의 최소값) / (x의 최대값 - x의 최소값)\n",
    "\n",
    "**사이킷런의 전처리에서 제공하는 Normalizaer**\n",
    "- 선형대수에서의 정규화 개념이 적용. 개별 벡터의 크기를 맞추기 위해 변환하는 것.\n",
    "- 개별 벡터를 모든 피처 벡터의 크기로 나눈다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StandardScaler\n",
    "표준화를 쉽게 지원하기 위한 클래스. 즉 개별 피처를 평균이 0이고 분산이 1인 값으로 변환.\n",
    "가우시안 정규 분포를 가질 수 있도록 데이터를 변환."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균값\n",
      "sepal length (cm)    5.843333\n",
      "sepal width (cm)     3.057333\n",
      "petal length (cm)    3.758000\n",
      "petal width (cm)     1.199333\n",
      "dtype: float64\n",
      "\n",
      "feature들의 분산 값\n",
      "sepal length (cm)    0.685694\n",
      "sepal width (cm)     0.189979\n",
      "petal length (cm)    3.116278\n",
      "petal width (cm)     0.581006\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# 붓꽃 데이터 세트를 로딩하고 DataFrame으로 변환\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_df = pd.DataFrame(iris.data, columns =  iris.feature_names)\n",
    "\n",
    "print('feature들의 평균값')\n",
    "print(iris_df.mean())\n",
    "\n",
    "print('\\nfeature들의 분산 값')\n",
    "print(iris_df.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature들의 평균 값\n",
      "sepal length (cm)   -1.690315e-15\n",
      "sepal width (cm)    -1.842970e-15\n",
      "petal length (cm)   -1.698641e-15\n",
      "petal width (cm)    -1.409243e-15\n",
      "dtype: float64\n",
      "\n",
      "feature들의 분산 값\n",
      "sepal length (cm)    1.006711\n",
      "sepal width (cm)     1.006711\n",
      "petal length (cm)    1.006711\n",
      "petal width (cm)     1.006711\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# StandardScaler로 데이터 세트 변환. fit()과 transform() 호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform() 시 스케일 변환된 데이터가 Numpy ndarray로 반환돼 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
    "print('feature들의 평균 값')\n",
    "print(iris_df_scaled.mean())\n",
    "\n",
    "print('\\nfeature들의 분산 값')\n",
    "print(iris_df_scaled.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler\n",
    "데이터를 0과 1사이의 범위 값으로 변환. (음수 값이 있으면 -1~1 값으로 변환)  \n",
    "데이터의 분포가 가우시안 분포가 아닐 경우에 Min, Max Scale을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "피처들의 최솟값\n",
      "sepal length (cm)    0.0\n",
      "sepal width (cm)     0.0\n",
      "petal length (cm)    0.0\n",
      "petal width (cm)     0.0\n",
      "dtype: float64\n",
      "\n",
      "feature들의 최댓값\n",
      "sepal length (cm)    1.0\n",
      "sepal width (cm)     1.0\n",
      "petal length (cm)    1.0\n",
      "petal width (cm)     1.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMaxScaler 객체 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# MinMaxScaler로 데이터 세트 변환. fit()과 transform() 호출\n",
    "scaler.fit(iris_df)\n",
    "iris_scaled = scaler.transform(iris_df)\n",
    "\n",
    "# transform() 시 스케일 변환된 데이터 세트가 Numpy ndarray로 반환돼 이를 DataFrame으로 변환\n",
    "iris_df_scaled = pd.DataFrame(data = iris_scaled, columns = iris.feature_names)\n",
    "\n",
    "print('피처들의 최솟값')\n",
    "print(iris_df_scaled.min())\n",
    "print('\\nfeature들의 최댓값')\n",
    "print(iris_df_scaled.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점\n",
    "StandardScaler나 MinMaxScaler와 같은 Scaler 객체를 이용해 데이터의 스케일링 변환 시 fit(), transform(), fit_transform() 메소드를 이용한다.  \n",
    "- fit(): 데이터 변환을 위한 기준 정보 설정 적용\n",
    "- transform(): 설정된 정보를 이용해 데이터를 변환\n",
    "- fit_transform(): fit(), transform()을 한번에 적용\n",
    "\n",
    "학습 데이터 세트와 테스트 데이터 세트에 fit(), transform()을 적용할 때 유의점\n",
    "Scaler 객체를 이용해 학습 데이터 세트로 fit()과 transform()을 적용하면 **테스트 데이터 세트로는 다시 fit()을 수행하지 않고 학습 데이터 세트로 fit()을 수행한 결과를 이용해 transform()변환을 적용해야 한다.** 즉, 학습 데이터로 fit()이 적용된 스케일링 기준 정보를 그대로 테스트 데이터에 적용해야 하며, 그렇지 않고 테스트 데이터로 다시 새로운 스케일링 기준을 만들게 되면 학습 데이터와 테스트 데이터의 스케일링 기준 정보가 서로 달라지기 때문에 올바른 예측 결과를 도출하지 못한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 학습 데이터는 0부터 10까지, 테스트 데이터는 0부터 5까지 값을 가지는 데이터 세트 생성\n",
    "# Scaler 클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1, 1)로 차원 변경\n",
    "\n",
    "train_array = np.arange(0, 11).reshape(-1,1)\n",
    "test_array = np.arange(0, 6).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터:  [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "scale된 train_array 데이터:  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0~1 값으로 변환\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fit() 하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10으로 설정\n",
    "scaler.fit(train_array)\n",
    "\n",
    "# 1/10 scale로 train_array 데이터 변환함. 원본 10 -> 1 로 변환됨\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('원본 train_array 데이터: ', np.round(train_array.reshape(-1), 2))\n",
    "print('scale된 train_array 데이터: ', np.round(train_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 test_array 데이터:  [0 1 2 3 4 5]\n",
      "scale된 test_array 데이터:  [0.  0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\n",
    "scaler.fit(test_array)\n",
    "\n",
    "# 1/5 scale로 test_array 데이터 변환함. 원본 5 -> 1로 변환.\n",
    "test_scaled = scaler.transform(test_array)\n",
    "\n",
    "# test_array의 scale 변환 출력\n",
    "print('원본 test_array 데이터: ', np.round(test_array.reshape(-1), 2))\n",
    "print('scale된 test_array 데이터: ', np.round(test_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터와 테스트 데이터의 스케일링이 맞지 않다. 학습 데이터와 테스트 데이터의 서로 다른 원본값이 동일한 값으로 반환되는 결과를 초래한다. 머신러닝 모델은 학습 데이터를 기반으로 학습되기 때문에 반드시 테스트 데이터는 학습 데이터의 스케일링 기준에 따라야 하며, 테스트 데이터의 1 값은 학습 데이터와 동일하게 0.1 값으로 변환돼야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 train_array 데이터:  [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "scale된 train_array 데이터:  [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n",
      "원본 test_array 데이터:  [0 1 2 3 4 5]\n",
      "scale된 test_array 데이터:  [0.  0.1 0.2 0.3 0.4 0.5]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_array)\n",
    "train_scaled = scaler.transform(train_array)\n",
    "\n",
    "print('원본 train_array 데이터: ', np.round(train_array.reshape(-1), 2))\n",
    "print('scale된 train_array 데이터: ', np.round(train_scaled.reshape(-1), 2))\n",
    "\n",
    "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform()만으로 변환해야 함\n",
    "test_scaled = scaler.transform(test_array)\n",
    "print('원본 test_array 데이터: ', np.round(test_array.reshape(-1), 2))\n",
    "print('scale된 test_array 데이터: ', np.round(test_scaled.reshape(-1), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_transform()을 적용할 때도 마찬가지. fit_transform()은 fit()과 transform()을 순차적으로 수행하는 메소드이므로 학습 데이터에서는 상관없지만 테스트 데이터에서는 절대 사용해서는 안된다.  \n",
    "이렇게 학습과 테스트 데이터에 fit()과 transform()을 적용할 때 주의사항이 발생하므로 학습과 테스트 데이터 세트로 분리하기 전에 먼저 전체 데이터 세트에 스케일링을 적용한 뒤 학습과 테스트 데이터 세트로 분리하는 것이 더 바람직하다.  \n",
    "유의할 점 요약  \n",
    "1. 가능하다면 전체 데이터의 스케일링 변환을 적용한 뒤 학습과 테스트 데이터로 분리\n",
    "2. 1이 여의치 않다면 테스트 데이터 변환 시에는 fit()이나 fit_transform()을 적용하지 않고 학습 데이터로 이미 fit()된 Scaler 객체를 이용해 transform()으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
