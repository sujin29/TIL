{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 03 평가\n",
    "머신러닝 프로세스 - 데이터 가공/변환, 모델 학습/예측, 평가  \n",
    "타이타닉 생존자 예제 모델 예측 성능 평가를 위해 정확도(Accuracy)를 이용했다.  \n",
    "성능 평가 지표(Evaluation Metric)는 일반적으로 모델이 분류냐 회귀냐에 따라 여러 종류로 나뉜다.  \n",
    "\n",
    "**회귀**: 실제 값과 예측값의 오차 평균값에 기반.\n",
    "- 오차에 절댓값을 씌운 뒤 평균 오차 계산\n",
    "- 오차의 제곱 값에 루트를 씌운 뒤 평균 오차 계산\n",
    "-> 예측 오차를 가지고 정규화 수준을 재가공\n",
    "\n",
    "분류의 평가방법도 실제 결과 데이터와 예측 결과 데이터가 얼마나 정확하고 오류가 적게 발생하는가에 기반하지만, 단순히 정확도만 가지고 판단했다가는 잘못된 평가 결과에 빠질 수 있다.\n",
    "\n",
    "특히 0과 1로 결정값이 한정되는 이진 분류에서는 정확도보다는 다른 성능 평가 지표가 더 중요시되는 경우가 많다.\n",
    "\n",
    "#### 분류의 성능 평가 지표\n",
    "- 정확도(Accuracy)\n",
    "- 오차행렬(Confusion Matrix)\n",
    "- 정밀도(Precision)\n",
    "- 재현율(Recall)\n",
    "- F1 스코어\n",
    "- ROC AUC\n",
    "\n",
    "분류는 결정 클래스 값 종류의 유형에 따라 긍정/부정과 같은 2개의 결괏값을 가지는 이진 분류와 여러 개의 결정 클래스 값을 가지는 멀티 분류로 나뉜다. 위의 지표는 이진/멀티 분류 모두에 적용되는 지표이지만, 특히 이진 분류에서 더욱 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도(Accuracy)\n",
    "정확도: 실제 데이터에서 예측 데이터가 얼마나 같은지를 판단하는 지표\n",
    "\n",
    "> 정확도 = 예측 결과가 동일한 데이터 건수 / 전체 예측 데이터 건수\n",
    "\n",
    "직관적으로 예측 성능을 나타내는 평가 지표이다. 하지만 이진 분류의 경우 데이터 구성에 따라 ML 모델의 성능을 왜곡할 수 있기 때문에 정확도 수치 하나만 가지고 성능을 평가하지 않는다.\n",
    "\n",
    "**정확도 지표가 모델 성능을 왜곡하는 예제 - 타이타닉**  \n",
    "ML 알고리즘 적용 후 예측 정확도 결과 보통 80% 대. 탑승객이 남자인 경우보다 여자인 경우에 생존 확률이 높았기 때문에 별다른 알고리즘의 적용 없이 무조건 성별이 여자인 경우 - 생존, 남자인 경우 - 사망으로 예측해도 비슷한 수치가 나온다.\n",
    "\n",
    "`BaseEstimator` 클래스: Customized 형태의 Estimator를 개발자가 생성할 수 있다.  \n",
    "`MyDummyClassifier` 클래스: 학습을 수행하는 fit()메서드는 아무것도 수행하지 않으며 예측을 수행하는 predict() 메서드는 단순히 Sex 피처가 1이면 0, 그렇지 않으면 1로 예측."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit() 메서드는 아무것도 학습하지 않음\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    # predict() 메서드는 단순히 Sex 피처가 1이면 0, 그렇지 않으면 1로 예측함\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros(( X.shape[0], 1 ))\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else:\n",
    "                pred[i] = 1\n",
    "                \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "## Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "## 머신러닝에 불필요한 피처 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "## Label Encoding 수행\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "## 앞에서 실행한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier의 정확도는: 0.7877\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
    "titanic_df = pd.read_csv('../../data/train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis = 1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, \n",
    "                                                    y_titanic_df,\n",
    "                                                    test_size = .2,\n",
    "                                                    random_state = 0)\n",
    "\n",
    "# 위에서 생성한 Dummy Classifier를 이용해 학습/예측/평가 수행\n",
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train, y_train)\n",
    "\n",
    "mypredictions = myclf.predict(X_test)\n",
    "print('Dummy Classifier의 정확도는: {0:.4f}'.format(accuracy_score(y_test, mypredictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단순한 알고리즘으로 예측을 하더라도 데이터의 구성에 따라 정확도 결과는 약 78.77%로 꽤 높은 수치가 나올 수 있기에 정확도를 평가 지표로 사용할 때는 매우 신중해야 한다. 특히 정확도는 **불균형한(imbalanced) 레이블 값 분포에서** ML 모델의 성능을 판단할 경우, 적합한 평가 지표가 아니다. 예를 들어 100개의 데이터 중 90개의 데이터 레이블이 0, 단 10개의 데이터 레이블이 1이라고 한다면 무조건 0으로 예측 결과를 반환하는 ML 모델의 경우라도 정확도가 90%가 된다.  \n",
    "#### MNIST 데이터 세트\n",
    "0부터 9까지의 숫자 이미지의 픽셀 정보를 가지고 있으며, 이를 기반으로 숫자 Digit을 예측하는데 사용된다. `load_digits()`   \n",
    "0부터 9까지 있는 멀티 레이블 분류를 위한 데이터 세트. 이것을 레이블 값이 7인 것만 True, 나머지 값은 모두 False로 변환해 이진 분류로 바꿔보면 전체 데이터의 10%만 True, 나머지 90%는 False인 불균형한 데이터 세트로 변형.  \n",
    "이렇게 불균형한 데이터세트에 모든 데이터를 False, 즉 0으로 예측하는 classifier를 이용해 정확도를 측정하면 90%에 가까운 예측 정확도를 나타낸다. **하나로 찍어도 데이터 분포도가 균일하지 않은 경우 높은 수치가 나타난다는 것이 정확도 평가 지표의 맹점이다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class MyFakeClassifier(BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "    \n",
    "    # 입력값으로 들어오는 X 데이터 세트의 크기만큼 모두 0으로 만들어서 반환\n",
    "    def predict(self, X):\n",
    "        return np.zeros( (len(X), 1), dtype=bool)\n",
    "\n",
    "# 사이킷런의 내장 데이터 세트인 load_digits()를 이용해 MNIST 데이터 로딩\n",
    "digits = load_digits()\n",
    "\n",
    "# digits 번호가 7번이면 True이고 이를 astype(int)로 1로 변환, \n",
    "# 7번이 아니면 False이고 0으로 변환\n",
    "\n",
    "y = (digits.target == 7).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, y,\n",
    "                                                   random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "레이블 테스트 세트 크기:  (450,)\n",
      "테스트 세트 레이블 0과 1의 분포도\n",
      "0    405\n",
      "1     45\n",
      "dtype: int64\n",
      "모든 예측을 0으로 하여도 정확도는: 0.900\n"
     ]
    }
   ],
   "source": [
    "# 불균형한 레이블 데이터 분포도 확인\n",
    "print('레이블 테스트 세트 크기: ', y_test.shape)\n",
    "print('테스트 세트 레이블 0과 1의 분포도')\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "# Dummy Classifier로 학습/예측/정확도 평가\n",
    "fakeclf = MyFakeClassifier()\n",
    "fakeclf.fit(X_train, y_train)\n",
    "fakepred = fakeclf.predict(X_test)\n",
    "print('모든 예측을 0으로 하여도 정확도는: {:.3f}'.format(accuracy_score(y_test, fakepred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도 평가 지표는 불균형한 레이블 데이터 세트에서는 성능 수치로 사용돼서는 안된다. 이러한 한계점을 극복하기 위해 여러 가지 분류 지표와 함께 적용해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 오차행렬\n",
    "오차행렬(confusion matrix, 혼동행렬): 이진 분류에서 성능 지표로 잘 활용된다. 학습된 분류 모델이 예측을 수행하면서 얼마나 헷갈리고(confused) 있는지도 함께 보여주는 지표.  \n",
    "오차행렬은 4분면 행렬에서 실제 레이블 클래스 값과 예측 레이블 클래스 값이 어떠한 유형을 가지고 매핑되는지 나타낸다.\n",
    "\n",
    "||Negative(0)|Positive(1)|\n",
    "|-----------|:-----------:|:-----------:|\n",
    "|Negative(0)|TN|FP|\n",
    "|Positive(1)|FN|TP|\n",
    "\n",
    "\n",
    "앞 문자 True/False는 예측값과 실제값이 '같은가/틀린가'를 의미.  \n",
    "뒤 문자 Negative/Positive는 예측 결과 값이 부정(0)/긍정(1)을 의미.\n",
    "- TN: 예측값을 Negative값 0으로 예측했고 실제값 역시 Negative 0\n",
    "- FP: 예측값을 Positive값 1로 예측했는데 실제값은 Negative 0\n",
    "- FN: 예측값을 Negative값 0으로 예측했는데 실제값은 Positive 1\n",
    "- TP: 예측값을 Positive값 1로 예측했고 실제값 역시 Positive 1\n",
    "\n",
    "`confusion_matrix()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[405,   0],\n",
       "       [ 45,   0]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, fakepred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||Negative(0)|Positive(1)|\n",
    "|-----------|:-----------:|:-----------:|\n",
    "|Negative(0)|TN - 405|FP - 0|\n",
    "|Positive(1)|FN - 45|TP - 0|\n",
    "\n",
    "TP, TN, FP, FN 값은 Classifier 성능의 여러 면모를 판단할 수 있는 기반 정보를 제공한다. 이 값을 조합해 Classifier의 성능을 측정할 수 있는 주요 지표인 정확도(Accuracy), 정밀도(Precision), 재현율(Recall) 값을 알 수 있다.  \n",
    "정확도는 예측값과 실제값이 얼마나 동일한가에 대한 비율만으로 결정된다. 즉 오차행렬에서 True에 해당하는 값인 TN과 TP에 좌우된다.\n",
    "> 정확도 = 예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수  \n",
    "정확도 = (TN + TP) / (TN + FP + FN + TP)\n",
    "\n",
    "일반적으로 불균형한 레이블 클래스를 가지는 이진 분류 모델에서는 많은 데이터 중에 중점적으로 찾아야 하는 매우 적은 수의 결괏값에 Positive를 설정해 1값을 부여하고, 그렇지 않은 경우는 Negative로 0을 부여하는 경우가 많다. 예를 들어 사기 행위 예측 모델에서는 사기 행위가 Positive, 정상 행위가 Negative. 암 검진 예측 모델에서는 암이 양성일 경우 Positive, 암이 음성일 경우 Negative로 할당되는 경우가 일반적.  \n",
    "불균형한 이진 분류 데이터 세트에서는 Positive 데이터 건수가 매우 작기 때문에 데이터에 기반한 ML 알고리즘은 Positive보다는 Negative로 예측 시 정확도가 높아지는 경향이 발생한다. 10,000 건의 데이터 세트에서 9,900 건이 Negative이고 100 건이 Positive라면 Negative로 예측하는 경향이 더 강해져서 TN이 매우 커지고 TP는 매우 작아지게 된다. 또한 Negative로 예측할 때 정확도가 높기 때문에 FN이 매우 작고, Positive로 예측하는 경우가 작기 때문에 FP 역시 매우 작아진다. 결과적으로 정확도 지표는 비대칭한 데이터 세트에서 Positive에 대한 예측 정확도를 판단하지 못한 채 Negative에 대한 예측 정확도만으로 분류의 정확도가 매우 높게 나타나는 수치적인 판단 오류를 일으키게 된다.  \n",
    "불균형한 데이터 세트에서 정확도보다 더 선호되는 평가 지표인 정밀도(Precision), 재현율(Recall)이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 정밀도와 재현율\n",
    "정밀도와 재현율은 Positive 데이터 세트의 예측 성능에 좀 더 초점을 맞춘 평가 지표이다. 앞서 만든 MyFakeClassifier는 Positive로 예측한 TP값이 하나도 없기 때문에 정밀도와 재현율 값이 모두 0이다.\n",
    "> 정밀도 = TP / (FP + TP)  \n",
    "재현율 = TP / (FN + TP)\n",
    "\n",
    "#### 정밀도\n",
    ": 예측을 Positive로 한 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율  \n",
    "분모 **FP + TP**는 예측을 Positive로 한 모든 데이터 건수. 분자 **TP**는 예측과 실제 값이 Positive로 일치한 데이터 건수. Positive 예측 성능을 더욱 정밀하게 측정하기 위한 평가 지표로 **양성 예측도**라고도 불린다.  \n",
    "#### 재현율\n",
    ": 실제 값이 Positive인 대상 중에 예측과 실제 값이 Positive로 일치한 데이터의 비율  \n",
    "분모 **FN + TP**는 실제 값이 Positive인 모든 데이터 건수. 분자 **TP**는 예측과 실제 값이 Positive로 일치한 데이터 건수. **민감도(sensitivity) 또는 TPR(True Positive Rate)**라고도 불린다.  \n",
    "\n",
    "정밀도와 재현율 지표 중에 이진 분류 모델의 업무 특성에 따라서 특정 평가 지표가 더 중요한 지표로 간주될 수 있다. **재현율이 중요 지표인 경우는 실제 Positive 양성 데이터를 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우**이다. 예를 들어 암 판단 모델은 재현율이 훨씬 중요하다. 실제 Positive인 암 환자를 Positive 양성이 아닌 Negative 음성으로 잘못 판단했을 경우 오류의 대가가 생명을 앗아갈 정도로 심각하기 때문. 반면에 실제 Negative인 건강한 환자를 암 환자인 Positive로 예측한 경우면 다시 한번 재검사를 하는 수준의 비용이 소모된다.  \n",
    "보험 사기와 같은 금융 사기 적발 모델도 재현율이 중요. 실제 금융거래 사기인 Positive 건을 Negative로 잘못 판단하게 되면 회사에 미치는 손해가 크다. 반면에 정상 금융거래인 Negative를 금융사기인 Positive로 잘못 판단하더라도 재확인하는 절차를 가동하면 된다.  \n",
    "보통은 재현율이 정밀도보다 상대적으로 중요한 업무가 많지만, 정밀도가 더 중요한 지표인 경우도 있다. 스팸메일 여부를 판단하는 모델의 경우 실제 Positive인 스팸 메일을 Negative인 일반 메일로 분류하더라도 사용자가 불편함을 느끼는 정도이지만, 실제 Negative인 일반 메일을 Positive인 스팸메일로 분류할 경우에는 메일을 아예 받지 못하게 돼 업무에 차질이 생긴다.  \n",
    "(정밀도 Positive로 잘못 예측한거 / 재현율 Positive를 못잡은거)\n",
    "- 재현율이 상대적으로 더 중요한 지표인 경우: 실제 Positive 양성인 데이터 예측을 Negative로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우\n",
    "- 정밀도가 상대적으로 더 중요한 지표인 경우: 실제 Negative 음성인 데이터 예측을 Positive로 잘못 판단하게 되면 업무상 큰 영향이 발생하는 경우\n",
    "\n",
    "> 정밀도 = TP / (FP + TP)  \n",
    "재현율 = TP / (FN + TP)\n",
    "\n",
    "재현율과 정밀도 모두 TP를 높이는 데 동일하게 초점을 맞추지만, 재현율은 FN(실제 Positive, 예측 Negative)을 낮추는데, 정밀도는 FP를 낮추는 데 초점을 맞춘다. 이 같은 특성 때문에 재현율과 정밀도는 서로 보완적인 지표로 분류의 성능을 평가하는 데 적용된다. 가장 좋은 성능 평가는 재현율과 정밀도 모두 높은 수치를 얻는 것. 둘 중 어느 한 평가 지표만 매우 높고, 다른 수치는 매우 낮은 결과를 나타내는 경우 바람직하지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "타이타닉 예제에서 오차 행렬, 정밀도, 재현율 모두 구해서 예측 성능 평가하기.  \n",
    "`precision_score()` : 정밀도 계산  \n",
    "`recall_score()`: 재현율 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = precision_score(y_test, pred)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[104  14]\n",
      " [ 13  48]]\n",
      "정확도: 0.8492, 정밀도: 0.7742, 재현율: 0.7742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wnsgo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 원본 데이터를 재로딩, 데이터 가공, 학습 데이터/테스트 데이터 분할\n",
    "titanic_df = pd.read_csv('../../data/train.csv')\n",
    "y_titanic_df = titanic_df['Survived']\n",
    "X_titanic_df = titanic_df.drop('Survived', axis = 1)\n",
    "X_titanic_df = transform_features(X_titanic_df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, \n",
    "                                                    y_titanic_df, \n",
    "                                                    test_size = .2, \n",
    "                                                    random_state=11)\n",
    "lf_clf = LogisticRegression()\n",
    "\n",
    "lf_clf.fit(X_train, y_train)\n",
    "pred = lf_clf.predict(X_test)\n",
    "get_clf_eval(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
