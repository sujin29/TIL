{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증을 보다 간편하게 - cross_val_score()\n",
    "1. 폴드 세트 설정\n",
    "2. for 루프에서 반복으로 학습 및 테스트 데이터의 인덱스를 추출한 뒤\n",
    "3. 반복적으로 학습과 예측을 수행하고 예측성능을 반환\n",
    "\n",
    "일련의 과정을 한꺼번에 수행해주는 API\n",
    "\n",
    "cross_val_score(`estimator`, `X`, `y = None`, `scoring = None`, `cv = None`, \n",
    "n_jobs = 1, verbose = 0, fit_params = None, pre_dispatch = '2*n_jobs')\n",
    "\n",
    "**주요 파라미터**\n",
    "- `estimator` : Classifier 또는 Regressor와 같은 사이킷런 알고리즘 클래스\n",
    "- `X` : 피처 데이터 세트\n",
    "- `y` : 레이블 데이터 세트\n",
    "- `scoring` : 예측 성능 평가 지표\n",
    "- `cv` : 교차 검증 폴드 수\n",
    "\n",
    "**수행 후 반환 값**  \n",
    ": 성능 지표 측정값을 배열 형태로 반환\n",
    "\n",
    "`estimatror`가 classifier일 경우 Stratified K Fold방식으로 학습/테스트 세트 분할.\n",
    "회귀인 경우 K Fold 방식으로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wnsgo\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 별 정확도:  [0.98 0.94 0.98]\n",
      "평균 검증 정확도:  0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
    "scores = cross_val_score(dt_clf, data, label, scoring = 'accuracy', cv = 3)\n",
    "print('교차 검증 별 정확도: ', np.round(scores, 4))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val_score()는 cv로 지정된 횟수만큼 scoring 파라미터로 지정된 평가 지표로 평가 결괏값을 배열로 반환. 이를 평균해 평가 수치로 사용.  \n",
    "cross_val_score()는 내부에서 Estimator를 학습(fit), 예측(predict), 평가(evaluation)시켜주므로 간단하게 교차 검증을 수행할 수 있다.  \n",
    "cross_val_score() 수행결과와 StratifiedKfold의 교차 검증별 정확도와 평균 검증 정확도가 모두 동일하다. cross_val_score()가 내부적으로 StratifiedKFold를 이용하기 때문."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증 별 정확도 [0.98, 0.94, 0.98]\n",
      "평균 검증 정확도 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=3)\n",
    "sk_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_index, test_index in skfold.split(data, label):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "    \n",
    "    sk_clf.fit(X_train, y_train)\n",
    "    pred = sk_clf.predict(X_test)\n",
    "    \n",
    "    n_iter +=1\n",
    "    \n",
    "    cv_accuracy.append(np.round(accuracy_score(y_test, pred), 4))\n",
    "    \n",
    "print('교차 검증 별 정확도', cv_accuracy)\n",
    "print('평균 검증 정확도', np.round(np.mean(cv_accuracy), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cross_validate()\n",
    "cross_val_score()는 단 하나의 평가 지표만 가능하지만 `cross_validate()`는 여러 개의 평가 지표를 반환할 수 있다. 또한 학습 데이터에 대한 성능 평가 지표와 수행 시간도 같이 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.00141144, 0.        , 0.00099659]), 'score_time': array([0.        , 0.00099516, 0.        ]), 'test_score': array([0.98, 0.94, 0.98])}\n",
      "**************************************************\n",
      "교차 검증 별 정확도:  [0.98 0.94 0.98]\n",
      "평균 검증 정확도 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state = 156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
    "scores = cross_validate(dt_clf, data, label, scoring = 'accuracy', cv = 3)\n",
    "\n",
    "print(scores)\n",
    "print('*'*50)\n",
    "print('교차 검증 별 정확도: ', scores['test_score'])\n",
    "print('평균 검증 정확도', np.round(np.mean(scores['test_score']), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV   - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에\n",
    "**하이퍼 파라미터**  \n",
    ": 머신러닝 알고리즘을 구성하는 주요 구성 요소. 이 값을 조정해 알고리즘의 예측 성능을 개선할 수 있다.  \n",
    "`GridSearchCV` API를 이용해 Classifier나 Regressor와 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출할 수 있는 방안을 제공."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_parameters = {'max_depth': [1, 2, 3],\n",
    "                   'min_samples_split': [2, 3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같이 순차적으로 적용. 6회에 걸쳐 파라미터를 순차적으로 바꿔 실행하면서 최적의 파라미터와 수팽결과를 도출."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|순번 | max_depth | min_samples_split|\n",
    "|-----|-----------|------------------|\n",
    "|**1** | 1 | 2|\n",
    "|**2** | 1 | 3|\n",
    "|**3** | 2 | 2|\n",
    "|**4** | 2 | 3|\n",
    "|**5** | 3 | 2|\n",
    "|**6** | 3 | 3|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GirdSearchCV는 __교차 검증을 기반으로 하이퍼 파라미터의 최적 값을 찾게 해준다.__ 즉, 데이터 세트를 cross-validation을 위한 학습/테스트 세트로 자동으로 분할한 뒤에 하이퍼 파라미터 그리드에 기술된 모든 파라미터를 순차적으로 적용해 최적의 파라미터를 찾을 수 있게 해준다. \n",
    "사용자가 튜닝하고자 하는 여러 종류의 하이퍼 파라미터를 다양하게 테스트하면서 최적의 파라미터를 찾게 해주지만 순차적으로 파라미터를 테스트하므로 __수행시간이 상대적으로 오래 걸린다.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV 클래스의 생성자로 들어가는 주요 파라미터\n",
    "- estimator: classifier, regressor, pipeline 등\n",
    "- param_grid: key + 리스트 값을 가지는 딕셔너리. estimator의 튜닝을 위해 파라미터명과 사용될 여러 파라미터 값을 지정.\n",
    "- scoring: 예측 성능을 측정할 평가 방법 ('accuracy')\n",
    "- cv: 교차 검증을 위해 분할되는 학습/테스트 세트의 개수\n",
    "- refit: default = True, True로 생성 시 가장 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 하이퍼 파라미터로 재학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
    "\n",
    "iris_data = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data,\n",
    "                                                    iris_data.target,\n",
    "                                                    test_size = .2,\n",
    "                                                    random_state = 121)\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# 파라미터를 딕셔너리 형태로 설정\n",
    "parameters = {'max_depth': [1, 2, 3], 'min_samples_split': [2, 3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 데이터 세트를 GridSearchCV 객체의 fit 메서드에 인자로 입력\n",
    "GridSearchCV 객체의 fit메서드를 수행하면 학습 데이터를 cv에 기술된 폴딩 세트로 분할해 param_grid에 기술된 하이퍼 파라미터를 순차적으로 변경하면서 학습/평가를 수행하고 그 결과를 cv_results_ 속성에 기록\n",
    "`cv_results_`는 gridsearchcv의 결과 세트로서 딕셔너리 형태로 key값과 리스트 형태의 value값을 가진다. DataFrame으로 변환하면 내용을 좀 더 쉽게 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 \n",
    "# refit = True가 default. True이면 가장 좋은 설정으로 재학습시킴\n",
    "\n",
    "grid_dtree = GridSearchCV(dtree, param_grid = parameters, cv=3, refit = True)\n",
    "\n",
    "# iris 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', \n",
    "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**주요 컬럼 별 의미**\n",
    "- params: 수행할 때마다 적용된 개별 하이퍼 파라미터 값\n",
    "- rank_test_score: 하이퍼 파라미터 별로 성능이 좋은 score 순위. 1이 가장 뛰어난 순위이며 이때의 파라미터가 최적의 하이퍼 파라미터이다.\n",
    "- mean_test_score: 개별 하이퍼 파라미터 별로 CV의 폴딩 테스트 세트에 대해 총 수행한 평가 평균값\n",
    "\n",
    "GridSearchCV 객체의 fit을 수행하면 최고 성능을 나타낸 하이퍼 파라미터의 값과 그 때의 평과 결과 값이 각각 `best_params_`, `best_scores_` 속성에 기록된다. (즉 cv_results_의 rank_test_score가 1일 때의 값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터:  {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 정확도:0.9750\n"
     ]
    }
   ],
   "source": [
    "print('GridSearchCV 최적 파라미터: ', grid_dtree.best_params_)\n",
    "print('GridSearchCV 최고 정확도:{0:.4f}'.format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도:0.9667\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습이 필요없음\n",
    "pred = estimator.predict(X_test)\n",
    "print('테스트 데이터 세트 정확도:{0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
